## 第三周工作总结

[github](https://github.com/crickwang/Low-Latency-LLM)

---

### 实现内容
- 将ASR-LLM-TTS流程与WebRTC整合，创建了部分可执行的工作流。
- ASR模型切换为Google STT服务。
- 在WebRTC客户端实现了更多录音的暂停和恢复功能。

#### ASR
切换到Google STT后，需要进行环境和token等额外设置。

### 遇到的挑战
遇到了这样一个bug：音频在服务端可播放、客户端可录制，但客户端无法正常播放声音。
- MediaTrack影响了音频播放。 :x:
- 不同采样率导致WebRTC的Peer Connection出现问题。 :x:
- 音频数据为空或因采样率、时间戳、计数器等参数被配置错导致音频失真。 :x:
    > 注意：音频在recv()函数中返回并送入WebRTC客户端之前一切正常。
- 创建了一个Dummy MediaTrack，不从TTS生成队列获取音频，而是直接生成正弦波形并在客户端播放。 :white_check_mark: 说明不是客户端问题。 :x:
- Timeframe设置太小，导致每个音频分块竞争播放。 :x: 后来加入了缓冲区合并所有分块，依然无声。
- 客户端未收到任何数据。 :x: 实际上是收到了。

### 下一步计划
- **紧急：解决上述bug。**
- 将EdgeTTS改造成API调用，实现与LLM输出同步的流式输出。也可考虑用Google TTS或微软Azure替代。
